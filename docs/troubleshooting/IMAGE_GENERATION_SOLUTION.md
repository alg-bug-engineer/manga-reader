# Gemini API å›¾ç‰‡ç”Ÿæˆé—®é¢˜è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆ

## é—®é¢˜åˆ†æ

### é”™è¯¯ä¿¡æ¯
```
AttributeError: 'GenerateContentResponse' object has no attribute 'parts'
```

### æ ¹æœ¬åŸå› 

**Gemini æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ç”Ÿæˆï¼**

- âŒ `gemini-2.0-flash-exp` - åªæ”¯æŒæ–‡æœ¬ç”Ÿæˆ
- âŒ `gemini-1.5-pro` - åªæ”¯æŒæ–‡æœ¬ç†è§£å’Œåˆ†æå›¾ç‰‡
- âŒ `gemini-1.5-flash` - åªæ”¯æŒæ–‡æœ¬ç†è§£å’Œåˆ†æå›¾ç‰‡

### æ­£ç¡®çš„å›¾ç‰‡ç”Ÿæˆæ–¹æ¡ˆ

Google æä¾›äº† **Imagen** æ¨¡å‹ç”¨äºå›¾ç‰‡ç”Ÿæˆï¼Œä½†è°ƒç”¨æ–¹å¼å’Œ Gemini ä¸åŒã€‚

## æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ Imagen APIï¼ˆæ¨èï¼‰

### å®‰è£…ä¾èµ–
```bash
uv pip install google-cloud-aiplatform
```

### ä½¿ç”¨ Imagen ç”Ÿæˆå›¾ç‰‡

```python
from google.cloud import aiplatform
import base64

# åˆå§‹åŒ–
aiplatform.init(project="your-project-id", location="us-central1")

# è°ƒç”¨ Imagen
model = aiplatform.Model("imagen-3.0-generate-001")

response = model.predict(
    prompt="A cute robot and a grumpy cat in manga style",
    parameters={
        "sample_count": 1,
        "aspect_ratio": "1:1"
    }
)

# è·å–å›¾ç‰‡
image_base64 = response.predictions[0].bytes_base64
image_data = base64.b64decode(image_base64)
```

## æ–¹æ¡ˆäºŒï¼šç»§ç»­ä½¿ç”¨ Geminiï¼ˆä½†åªèƒ½åˆ†æå›¾ç‰‡ï¼‰

å¦‚æœä½ åªæ˜¯æƒ³**ç†è§£**æˆ–**æè¿°**å›¾ç‰‡ï¼Œè€Œä¸æ˜¯ç”Ÿæˆæ–°å›¾ç‰‡ï¼š

```python
from google import genai

client = genai.Client(api_key=GEMINI_API_KEY)

# ä¸Šä¼ å›¾ç‰‡å¹¶è®© Gemini åˆ†æ
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=["Describe this image", image_file]
)

print(response.text)  # æ–‡æœ¬æè¿°
```

## æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨å…¶ä»–å›¾ç‰‡ç”ŸæˆæœåŠ¡

### é€‰é¡¹ A: OpenAI DALL-E
```python
from openai import OpenAI

client = OpenAI(api_key="your-key")

response = client.images.generate(
    model="dall-e-3",
    prompt="A cute robot and a grumpy cat",
    size="1024x1024"
)

image_url = response.data[0].url
```

### é€‰é¡¹ B: Stability AI
```python
import stability_sdk

client = stability_sdk.Client()

response = client.generate(
    prompt="A cute robot and a grumpy cat",
    steps=30
)
```

## å½“å‰é¡¹ç›®çš„æœ€ä½³æ–¹æ¡ˆ

è€ƒè™‘åˆ°é¡¹ç›®æ¶æ„ï¼Œå»ºè®®ï¼š

1. **è„šæœ¬ç”Ÿæˆ**: ç»§ç»­ä½¿ç”¨ Gemini âœ…
   ```
   gemini-2.0-flash-exp - å®Œç¾æ”¯æŒ
   ```

2. **å›¾ç‰‡ç”Ÿæˆ**: éœ€è¦åˆ‡æ¢åˆ° Imagen æˆ–å…¶ä»–æœåŠ¡

### å¿«é€Ÿä¿®å¤

#### é€‰é¡¹ 1: æ·»åŠ  DALL-E æ”¯æŒ

1. å®‰è£…ä¾èµ–:
```bash
npm install openai
```

2. æ›´æ–° `gemini_proxy_server.py`:

```python
@app.route('/api/generate-image', methods=['POST'])
def generate_image():
    # ... è·å–å‚æ•° ...

    # ä½¿ç”¨ OpenAI DALL-E
    from openai import OpenAI

    openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

    prompt = f"""Create a manga panel: {panel.get('sceneDescription')}
Characters: A cute robot with a screen face and a grumpy cat.
Dialogue: {panel.get('dialogue')}
Style: {style_prompts.get(style, style)}"""

    response = openai_client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        quality="standard",
        n=1,
    )

    image_url = response.data[0].url

    # ä¸‹è½½å›¾ç‰‡å¹¶è¿”å› base64
    import requests
    image_response = requests.get(image_url)
    image_data = base64.b64encode(image_response.content).decode('utf-8')

    return jsonify({
        "success": True,
        "imageData": image_data
    })
```

3. æ›´æ–° `.env.local`:
```
OPENAI_API_KEY=your-openai-key
```

#### é€‰é¡¹ 2: ä½¿ç”¨ Imagenï¼ˆéœ€è¦ GCP é¡¹ç›®ï¼‰

1. å®‰è£…ä¾èµ–:
```bash
uv pip install google-cloud-aiplatform
```

2. é…ç½® GCP è®¤è¯:
```bash
gcloud auth application-default login
```

3. æ›´æ–°ä»£ç ä½¿ç”¨ Imagen API

## ä¸´æ—¶è§£å†³æ–¹æ¡ˆ

å¦‚æœåªæ˜¯æƒ³æµ‹è¯•æµç¨‹ï¼Œå¯ä»¥ï¼š

1. **è¿”å›å ä½å›¾ç‰‡**
```python
# ç”Ÿæˆä¸€ä¸ªç®€å•çš„å ä½å›¾ç‰‡
from PIL import Image, ImageDraw, ImageFont

img = Image.new('RGB', (512, 512), color='white')
draw = ImageDraw.Draw(img)
draw.text((256, 256), f"Panel {panel.get('panelNumber')}", fill='black')

buffer = io.BytesIO()
img.save(buffer, format='PNG')
image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')

return jsonify({
    "success": True,
    "imageData": image_data
})
```

2. **ä½¿ç”¨é™æ€å›¾ç‰‡åº“**
```python
# è¿”å›é¢„è®¾çš„æ¼«ç”»æ ¼å›¾ç‰‡
import random

placeholder_images = [
    "base64_encoded_image_1",
    "base64_encoded_image_2",
    # ...
]

image_data = random.choice(placeholder_images)
```

## å»ºè®®çš„è¡ŒåŠ¨æ­¥éª¤

1. âœ… **çŸ­æœŸ**: ä½¿ç”¨å ä½å›¾ç‰‡æˆ– DALL-E
2. â³ **ä¸­æœŸ**: è¯„ä¼° Imagen æˆ–å…¶ä»–å›¾ç‰‡ç”ŸæˆæœåŠ¡
3. ğŸ¯ **é•¿æœŸ**: æ ¹æ®æˆæœ¬å’Œè´¨é‡é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ

## éœ€è¦å¸®åŠ©ï¼Ÿ

- æ£€æŸ¥ [Google Imagen æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview)
- æ£€æŸ¥ [OpenAI DALL-E æ–‡æ¡£](https://platform.openai.com/docs/guides/images)
- æµ‹è¯•è„šæœ¬ç”Ÿæˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
